{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrawdLLM Inference on TPU (JAX)\n",
    "\n",
    "This notebook implements transformer inference from scratch using JAX, running on Google TPU.\n",
    "\n",
    "**Setup:** Runtime > Change runtime type > TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tushar/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install huggingface_hub safetensors tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices: [CpuDevice(id=0)]\n",
      "Device count: 1\n"
     ]
    }
   ],
   "source": [
    "# Verify TPU is available\n",
    "import jax\n",
    "print(f\"Devices: {jax.devices()}\")\n",
    "print(f\"Device count: {jax.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weights from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: /Users/tushar/.cache/huggingface/hub/models--tsingla98--frawdllm-100m/snapshots/f74ba30cf03fb8928c261795cd7ee6c69e0f0e21/model.safetensors\n",
      "Tokenizer: /Users/tushar/.cache/huggingface/hub/models--tsingla98--frawdllm-100m/snapshots/f74ba30cf03fb8928c261795cd7ee6c69e0f0e21/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Download weights and tokenizer from HuggingFace\n",
    "weights_path = hf_hub_download(repo_id=\"tsingla98/frawdllm-100m\", filename=\"model.safetensors\")\n",
    "tokenizer_path = hf_hub_download(repo_id=\"tsingla98/frawdllm-100m\", filename=\"tokenizer.json\")\n",
    "\n",
    "print(f\"Weights: {weights_path}\")\n",
    "print(f\"Tokenizer: {tokenizer_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.blocks.0.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.0.attn.out_proj.bias: (768,)\n",
      "model.blocks.0.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.0.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.0.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.0.ln1.bias: (768,)\n",
      "model.blocks.0.ln1.weight: (768,)\n",
      "model.blocks.0.ln2.bias: (768,)\n",
      "model.blocks.0.ln2.weight: (768,)\n",
      "model.blocks.0.mlp.fc1.bias: (3072,)\n",
      "model.blocks.0.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.0.mlp.fc2.bias: (768,)\n",
      "model.blocks.0.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.1.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.1.attn.out_proj.bias: (768,)\n",
      "model.blocks.1.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.1.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.1.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.1.ln1.bias: (768,)\n",
      "model.blocks.1.ln1.weight: (768,)\n",
      "model.blocks.1.ln2.bias: (768,)\n",
      "model.blocks.1.ln2.weight: (768,)\n",
      "model.blocks.1.mlp.fc1.bias: (3072,)\n",
      "model.blocks.1.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.1.mlp.fc2.bias: (768,)\n",
      "model.blocks.1.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.10.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.10.attn.out_proj.bias: (768,)\n",
      "model.blocks.10.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.10.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.10.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.10.ln1.bias: (768,)\n",
      "model.blocks.10.ln1.weight: (768,)\n",
      "model.blocks.10.ln2.bias: (768,)\n",
      "model.blocks.10.ln2.weight: (768,)\n",
      "model.blocks.10.mlp.fc1.bias: (3072,)\n",
      "model.blocks.10.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.10.mlp.fc2.bias: (768,)\n",
      "model.blocks.10.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.11.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.11.attn.out_proj.bias: (768,)\n",
      "model.blocks.11.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.11.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.11.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.11.ln1.bias: (768,)\n",
      "model.blocks.11.ln1.weight: (768,)\n",
      "model.blocks.11.ln2.bias: (768,)\n",
      "model.blocks.11.ln2.weight: (768,)\n",
      "model.blocks.11.mlp.fc1.bias: (3072,)\n",
      "model.blocks.11.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.11.mlp.fc2.bias: (768,)\n",
      "model.blocks.11.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.2.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.2.attn.out_proj.bias: (768,)\n",
      "model.blocks.2.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.2.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.2.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.2.ln1.bias: (768,)\n",
      "model.blocks.2.ln1.weight: (768,)\n",
      "model.blocks.2.ln2.bias: (768,)\n",
      "model.blocks.2.ln2.weight: (768,)\n",
      "model.blocks.2.mlp.fc1.bias: (3072,)\n",
      "model.blocks.2.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.2.mlp.fc2.bias: (768,)\n",
      "model.blocks.2.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.3.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.3.attn.out_proj.bias: (768,)\n",
      "model.blocks.3.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.3.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.3.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.3.ln1.bias: (768,)\n",
      "model.blocks.3.ln1.weight: (768,)\n",
      "model.blocks.3.ln2.bias: (768,)\n",
      "model.blocks.3.ln2.weight: (768,)\n",
      "model.blocks.3.mlp.fc1.bias: (3072,)\n",
      "model.blocks.3.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.3.mlp.fc2.bias: (768,)\n",
      "model.blocks.3.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.4.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.4.attn.out_proj.bias: (768,)\n",
      "model.blocks.4.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.4.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.4.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.4.ln1.bias: (768,)\n",
      "model.blocks.4.ln1.weight: (768,)\n",
      "model.blocks.4.ln2.bias: (768,)\n",
      "model.blocks.4.ln2.weight: (768,)\n",
      "model.blocks.4.mlp.fc1.bias: (3072,)\n",
      "model.blocks.4.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.4.mlp.fc2.bias: (768,)\n",
      "model.blocks.4.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.5.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.5.attn.out_proj.bias: (768,)\n",
      "model.blocks.5.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.5.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.5.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.5.ln1.bias: (768,)\n",
      "model.blocks.5.ln1.weight: (768,)\n",
      "model.blocks.5.ln2.bias: (768,)\n",
      "model.blocks.5.ln2.weight: (768,)\n",
      "model.blocks.5.mlp.fc1.bias: (3072,)\n",
      "model.blocks.5.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.5.mlp.fc2.bias: (768,)\n",
      "model.blocks.5.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.6.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.6.attn.out_proj.bias: (768,)\n",
      "model.blocks.6.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.6.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.6.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.6.ln1.bias: (768,)\n",
      "model.blocks.6.ln1.weight: (768,)\n",
      "model.blocks.6.ln2.bias: (768,)\n",
      "model.blocks.6.ln2.weight: (768,)\n",
      "model.blocks.6.mlp.fc1.bias: (3072,)\n",
      "model.blocks.6.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.6.mlp.fc2.bias: (768,)\n",
      "model.blocks.6.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.7.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.7.attn.out_proj.bias: (768,)\n",
      "model.blocks.7.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.7.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.7.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.7.ln1.bias: (768,)\n",
      "model.blocks.7.ln1.weight: (768,)\n",
      "model.blocks.7.ln2.bias: (768,)\n",
      "model.blocks.7.ln2.weight: (768,)\n",
      "model.blocks.7.mlp.fc1.bias: (3072,)\n",
      "model.blocks.7.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.7.mlp.fc2.bias: (768,)\n",
      "model.blocks.7.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.8.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.8.attn.out_proj.bias: (768,)\n",
      "model.blocks.8.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.8.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.8.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.8.ln1.bias: (768,)\n",
      "model.blocks.8.ln1.weight: (768,)\n",
      "model.blocks.8.ln2.bias: (768,)\n",
      "model.blocks.8.ln2.weight: (768,)\n",
      "model.blocks.8.mlp.fc1.bias: (3072,)\n",
      "model.blocks.8.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.8.mlp.fc2.bias: (768,)\n",
      "model.blocks.8.mlp.fc2.weight: (768, 3072)\n",
      "model.blocks.9.attn.mask: (1, 1, 4096, 4096)\n",
      "model.blocks.9.attn.out_proj.bias: (768,)\n",
      "model.blocks.9.attn.out_proj.weight: (768, 768)\n",
      "model.blocks.9.attn.qkv_proj.bias: (2304,)\n",
      "model.blocks.9.attn.qkv_proj.weight: (2304, 768)\n",
      "model.blocks.9.ln1.bias: (768,)\n",
      "model.blocks.9.ln1.weight: (768,)\n",
      "model.blocks.9.ln2.bias: (768,)\n",
      "model.blocks.9.ln2.weight: (768,)\n",
      "model.blocks.9.mlp.fc1.bias: (3072,)\n",
      "model.blocks.9.mlp.fc1.weight: (3072, 768)\n",
      "model.blocks.9.mlp.fc2.bias: (768,)\n",
      "model.blocks.9.mlp.fc2.weight: (768, 3072)\n",
      "model.embeddings.token_emb.weight: (32000, 768)\n",
      "model.ln_f.bias: (768,)\n",
      "model.ln_f.weight: (768,)\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Load weights into JAX arrays\n",
    "weights = {}\n",
    "with safe_open(weights_path, framework=\"numpy\") as f:\n",
    "    for key in f.keys():\n",
    "        weights[key] = jnp.array(f.get_tensor(key))\n",
    "        print(f\"{key}: {weights[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import math\n",
    "\n",
    "EMBEDDINGS_WEIGHT_KEY = \"model.embeddings.token_emb.weight\"\n",
    "\n",
    "LN1_WEIGHT_FORMAT_PRE_ATTN_KEY = \"model.blocks.{}.ln1.weight\"\n",
    "LN1_BIAS_FORMAT_PRE_ATTN_KEY = \"model.blocks.{}.ln1.bias\"\n",
    "\n",
    "LN2_WEIGHT_FORMAT_PRE_ATTN_KEY = \"model.blocks.{}.ln2.weight\"\n",
    "LN2_BIAS_FORMAT_PRE_ATTN_KEY = \"model.blocks.{}.ln2.bias\"\n",
    "\n",
    "LNF_WEIGHT_FORMAT_KEY = \"model.ln_f.weight\"\n",
    "LNF_BIAS_FORMAT_KEY = \"model.ln_f.bias\"\n",
    "\n",
    "LM_HEAD_WEIGHT_KEY = \"model.embeddings.token_emb.weight\"  # tied weights\n",
    "\n",
    "QKV_WEIGHTS_KEY = \"model.blocks.{}.attn.qkv_proj.weight\"\n",
    "QKV_BIAS_KEY = \"model.blocks.{}.attn.qkv_proj.bias\"\n",
    "\n",
    "OUTPUT_PROJ_BIAS_KEY = \"model.blocks.{}.attn.out_proj.bias\"\n",
    "OUTPUT_PROJ_WEIGHT_KEY = \"model.blocks.{}.attn.out_proj.weight\"\n",
    "\n",
    "FC1_WEIGHT_KEY = \"model.blocks.{}.mlp.fc1.weight\"\n",
    "FC1_BIAS_KEY = \"model.blocks.{}.mlp.fc1.bias\"\n",
    "\n",
    "FC2_WEIGHT_KEY = \"model.blocks.{}.mlp.fc2.weight\"\n",
    "FC2_BIAS_KEY = \"model.blocks.{}.mlp.fc2.bias\"\n",
    "\n",
    "STOP_TOKEN_ID = 3\n",
    "\n",
    "EPSILON = 1e-5\n",
    "N_HEADS = 12\n",
    "N_LAYERS = 12\n",
    "HEAD_DIM = 64\n",
    "EMBEDDINGS_DIM = N_HEADS * HEAD_DIM\n",
    "ROPE_THETA = 10000.0\n",
    "TEMPERATURE = 0.5\n",
    "TOP_P = 0.9\n",
    "\n",
    "MAX_OUTPUT_TOKENS = 300\n",
    "MAX_CONTEXT_LENGTH = 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Implementation (JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: <|bos|><|user|>Hello, World!<|assistant|>\n",
      "Prompt length: 7 tokens\n",
      "Max new tokens: 300\n",
      "\n",
      "Compiling (first run)...\n",
      "First run (includes compilation): 8.459s\n",
      "Generated 300 tokens\n",
      "Output: Here's a step-by-step guide to creating a World of Warcraft Online:\n",
      "\n",
      "1. **Choose your location**: Pick a location that suits your interests, needs, and needs. Choose a location that suits your interests.\n",
      "\n",
      "2. **Choose a location**: Pick a location that suits your interests, needs, and needs. Choose a location that suits your interests.\n",
      "\n",
      "3. **Choose a location**: Pick a location that suits your interests, needs, and needs. Choose a location that suits your interests.\n",
      "\n",
      "4. **Pick a location**: Pick a location that suits your interests, needs, and needs. Choose a location that suits your interests.\n",
      "\n",
      "5. **Pick a location**: Pick a location that suits your interests, needs, and needs. Choose a location that suits your interests.\n",
      "\n",
      "6. **Pick a location**: Pick a location that suits your interests, needs, and needs. Choose a location that suits your interests.\n",
      "\n",
      "7. **Pick a location**: Pick a location that suits your interests, needs, and needs. Choose a location that suits your interests.\n",
      "\n",
      "8. **Track your progress**: Watch your progress or progress chart to see what you're seeing.\n",
      "\n",
      "**Pro tips**: Use a spreadsheet, game engine, or app to track your progress. Use a spreadsheet, or use a spreadsheet to track your progress\n",
      "\n",
      "Second run (cached)...\n",
      "Second run: 7.235s\n",
      "Tokens: 300, Speed: 41.5 tok/s\n",
      "Output: Welcome to the World! Here's a step-by-step guide to creating a World! Here's a step-by-step guide to creating a World!\n",
      "\n",
      "1. **Choose your path**: Pick a path that suits your interests and interests. Choose a specific path that suits your interests.\n",
      "\n",
      "2. **Choose a location**: Pick a spot that gets at least 6-8 hours of direct sunlight daily. Most places have a 3-6 day window.\n",
      "\n",
      "3. **Prepare your layout**: Set up a grid with a grid, grid, or grid layout. This helps you organize your layout.\n",
      "\n",
      "4. **Use a grid**: Use a grid grid with grid lines, grid lines, or grid lines. Use grid lines for navigation, navigation, and navigation.\n",
      "\n",
      "5. **Use a grid**: Use a grid grid with grid lines, grid lines, or grid lines. Use grid lines for navigation, navigation, and navigation.\n",
      "\n",
      "6. **Build a grid**: Use a grid grid with grid lines, grid lines, or grid lines. Create grid lines or grid lines for navigation and navigation.\n",
      "\n",
      "7. **Build a grid**: Use grid lines, grid lines, or grid lines to organize your layout.\n",
      "\n",
      "8. **Practice regularly**: Start with easy navigation, then gradually add more. This helps you find your perfect layout.\n",
      "\n",
      "9. **\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "def format_prompt(user_message: str) -> str:\n",
    "    return f\"<|bos|><|user|>{user_message}<|assistant|>\"\n",
    "\n",
    "\n",
    "def get_weights_tensor(key: str) -> jnp.ndarray:\n",
    "    return weights[key]\n",
    "\n",
    "\n",
    "def get_tokens_for_prompt(prompt: str) -> jnp.ndarray:\n",
    "    return jnp.array(tokenizer.encode(prompt, add_special_tokens=False).ids)\n",
    "\n",
    "\n",
    "# Precompute RoPE frequencies for max context length\n",
    "def _compute_rope_freqs(max_len: int) -> jnp.ndarray:\n",
    "    dim_indices = jnp.arange(0, HEAD_DIM, 2).astype(jnp.float32)\n",
    "    freqs = 1.0 / (ROPE_THETA ** (dim_indices / HEAD_DIM))\n",
    "    positions = jnp.arange(max_len).astype(jnp.float32)\n",
    "    angles = jnp.outer(positions, freqs)\n",
    "    return angles\n",
    "\n",
    "ROPE_FREQS = _compute_rope_freqs(MAX_CONTEXT_LENGTH)\n",
    "\n",
    "\n",
    "# === Stack all layer weights for vectorized access ===\n",
    "def _stack_weights():\n",
    "    \"\"\"Stack weights across layers for efficient access.\"\"\"\n",
    "    ln1_weights = jnp.stack([get_weights_tensor(LN1_WEIGHT_FORMAT_PRE_ATTN_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    ln1_biases = jnp.stack([get_weights_tensor(LN1_BIAS_FORMAT_PRE_ATTN_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    ln2_weights = jnp.stack([get_weights_tensor(LN2_WEIGHT_FORMAT_PRE_ATTN_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    ln2_biases = jnp.stack([get_weights_tensor(LN2_BIAS_FORMAT_PRE_ATTN_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    qkv_weights = jnp.stack([get_weights_tensor(QKV_WEIGHTS_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    qkv_biases = jnp.stack([get_weights_tensor(QKV_BIAS_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    out_weights = jnp.stack([get_weights_tensor(OUTPUT_PROJ_WEIGHT_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    out_biases = jnp.stack([get_weights_tensor(OUTPUT_PROJ_BIAS_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    fc1_weights = jnp.stack([get_weights_tensor(FC1_WEIGHT_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    fc1_biases = jnp.stack([get_weights_tensor(FC1_BIAS_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    fc2_weights = jnp.stack([get_weights_tensor(FC2_WEIGHT_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    fc2_biases = jnp.stack([get_weights_tensor(FC2_BIAS_KEY.format(i)) for i in range(N_LAYERS)])\n",
    "    \n",
    "    return {\n",
    "        'ln1_w': ln1_weights, 'ln1_b': ln1_biases,\n",
    "        'ln2_w': ln2_weights, 'ln2_b': ln2_biases,\n",
    "        'qkv_w': qkv_weights, 'qkv_b': qkv_biases,\n",
    "        'out_w': out_weights, 'out_b': out_biases,\n",
    "        'fc1_w': fc1_weights, 'fc1_b': fc1_biases,\n",
    "        'fc2_w': fc2_weights, 'fc2_b': fc2_biases,\n",
    "        'ln_f_w': get_weights_tensor(LNF_WEIGHT_FORMAT_KEY),\n",
    "        'ln_f_b': get_weights_tensor(LNF_BIAS_FORMAT_KEY),\n",
    "        'embed': get_weights_tensor(EMBEDDINGS_WEIGHT_KEY),\n",
    "        'lm_head': get_weights_tensor(LM_HEAD_WEIGHT_KEY),\n",
    "    }\n",
    "\n",
    "STACKED_WEIGHTS = _stack_weights()\n",
    "\n",
    "\n",
    "def apply_rope(x: jnp.ndarray, angles: jnp.ndarray) -> jnp.ndarray:\n",
    "    x_even = x[..., 0::2]\n",
    "    x_odd = x[..., 1::2]\n",
    "    cos = jnp.cos(angles)\n",
    "    sin = jnp.sin(angles)\n",
    "    x_even_rot = x_even * cos - x_odd * sin\n",
    "    x_odd_rot = x_even * sin + x_odd * cos\n",
    "    out = jnp.stack([x_even_rot, x_odd_rot], axis=-1)\n",
    "    out = out.reshape(x.shape)\n",
    "    return out\n",
    "\n",
    "\n",
    "def layer_norm(x, gamma, beta):\n",
    "    mean = x.mean(axis=-1, keepdims=True)\n",
    "    std = x.std(axis=-1, keepdims=True)\n",
    "    return (x - mean) / (std + EPSILON) * gamma + beta\n",
    "\n",
    "\n",
    "def decode_layer(layer_idx, x, k_cache, v_cache, cache_len, W):\n",
    "    \"\"\"Process one layer during decode (single token).\"\"\"\n",
    "    # LayerNorm 1\n",
    "    normed = layer_norm(x, W['ln1_w'][layer_idx], W['ln1_b'][layer_idx])\n",
    "    \n",
    "    # QKV projection\n",
    "    qkv = normed @ W['qkv_w'][layer_idx].T + W['qkv_b'][layer_idx]\n",
    "    q, k, v = jnp.split(qkv, 3, axis=-1)\n",
    "    \n",
    "    q = q.reshape(1, N_HEADS, HEAD_DIM).swapaxes(0, 1)\n",
    "    k = k.reshape(1, N_HEADS, HEAD_DIM).swapaxes(0, 1)\n",
    "    v = v.reshape(1, N_HEADS, HEAD_DIM).swapaxes(0, 1)\n",
    "    \n",
    "    # RoPE\n",
    "    angles = jax.lax.dynamic_slice(ROPE_FREQS, (cache_len, 0), (1, HEAD_DIM // 2))\n",
    "    q = apply_rope(q, angles)\n",
    "    k = apply_rope(k, angles)\n",
    "    \n",
    "    # Update cache\n",
    "    k_cache = k_cache.at[layer_idx, cache_len, :, :].set(k.swapaxes(0, 1)[0])\n",
    "    v_cache = v_cache.at[layer_idx, cache_len, :, :].set(v.swapaxes(0, 1)[0])\n",
    "    \n",
    "    # Attention over full cache with mask\n",
    "    k_full = k_cache[layer_idx].swapaxes(0, 1)\n",
    "    v_full = v_cache[layer_idx].swapaxes(0, 1)\n",
    "    \n",
    "    scores = (q @ k_full.swapaxes(-2, -1)) / math.sqrt(HEAD_DIM)\n",
    "    positions = jnp.arange(MAX_CONTEXT_LENGTH)\n",
    "    mask = jnp.where(positions <= cache_len, 0.0, -1e9)\n",
    "    scores = scores + mask\n",
    "    \n",
    "    attn = jax.nn.softmax(scores, axis=-1)\n",
    "    out = (attn @ v_full).swapaxes(0, 1).reshape(1, EMBEDDINGS_DIM)\n",
    "    \n",
    "    # Output projection + residual\n",
    "    out = out @ W['out_w'][layer_idx].T + W['out_b'][layer_idx] + x\n",
    "    \n",
    "    # MLP\n",
    "    normed2 = layer_norm(out, W['ln2_w'][layer_idx], W['ln2_b'][layer_idx])\n",
    "    hidden = jax.nn.gelu(normed2 @ W['fc1_w'][layer_idx].T + W['fc1_b'][layer_idx])\n",
    "    out = hidden @ W['fc2_w'][layer_idx].T + W['fc2_b'][layer_idx] + out\n",
    "    \n",
    "    return out, k_cache, v_cache\n",
    "\n",
    "\n",
    "def prefill_layer(layer_idx, x, k_cache, v_cache, W):\n",
    "    \"\"\"Process one layer during prefill (full sequence).\"\"\"\n",
    "    seq_len = x.shape[0]\n",
    "    \n",
    "    normed = layer_norm(x, W['ln1_w'][layer_idx], W['ln1_b'][layer_idx])\n",
    "    \n",
    "    qkv = normed @ W['qkv_w'][layer_idx].T + W['qkv_b'][layer_idx]\n",
    "    q, k, v = jnp.split(qkv, 3, axis=-1)\n",
    "    \n",
    "    q = q.reshape(seq_len, N_HEADS, HEAD_DIM).swapaxes(0, 1)\n",
    "    k = k.reshape(seq_len, N_HEADS, HEAD_DIM).swapaxes(0, 1)\n",
    "    v = v.reshape(seq_len, N_HEADS, HEAD_DIM).swapaxes(0, 1)\n",
    "    \n",
    "    angles = ROPE_FREQS[:seq_len]\n",
    "    q = apply_rope(q, angles)\n",
    "    k = apply_rope(k, angles)\n",
    "    \n",
    "    k_cache = k_cache.at[layer_idx, :seq_len, :, :].set(k.swapaxes(0, 1))\n",
    "    v_cache = v_cache.at[layer_idx, :seq_len, :, :].set(v.swapaxes(0, 1))\n",
    "    \n",
    "    scores = (q @ k.swapaxes(-2, -1)) / math.sqrt(HEAD_DIM)\n",
    "    mask = jnp.triu(jnp.ones((seq_len, seq_len)), k=1) * -1e9\n",
    "    scores = scores + mask\n",
    "    \n",
    "    attn = jax.nn.softmax(scores, axis=-1)\n",
    "    out = (attn @ v).swapaxes(0, 1).reshape(seq_len, EMBEDDINGS_DIM)\n",
    "    \n",
    "    out = out @ W['out_w'][layer_idx].T + W['out_b'][layer_idx] + x\n",
    "    \n",
    "    normed2 = layer_norm(out, W['ln2_w'][layer_idx], W['ln2_b'][layer_idx])\n",
    "    hidden = jax.nn.gelu(normed2 @ W['fc1_w'][layer_idx].T + W['fc1_b'][layer_idx])\n",
    "    out = hidden @ W['fc2_w'][layer_idx].T + W['fc2_b'][layer_idx] + out\n",
    "    \n",
    "    return out, k_cache, v_cache\n",
    "\n",
    "\n",
    "def sample_token(logits, key):\n",
    "    \"\"\"Sample next token with temperature and top-p.\"\"\"\n",
    "    probs = jax.nn.softmax(logits / TEMPERATURE)\n",
    "    top_probs, top_indices = jax.lax.top_k(probs, k=100)\n",
    "    sorted_idx = jnp.argsort(top_probs)[::-1]\n",
    "    sorted_probs = top_probs[sorted_idx]\n",
    "    cum_probs = jnp.cumsum(sorted_probs)\n",
    "    mask = (cum_probs <= TOP_P).at[0].set(True)\n",
    "    sorted_probs = jnp.where(mask, sorted_probs, 0.0)\n",
    "    \n",
    "    key, subkey = jax.random.split(key)\n",
    "    sampled = jax.random.categorical(subkey, jnp.log(sorted_probs + 1e-10))\n",
    "    next_token = top_indices[sorted_idx[sampled]]\n",
    "    \n",
    "    return next_token, key\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(1, 2))\n",
    "def generate(prompt_tokens, prompt_len, max_new_tokens, W, key):\n",
    "    \"\"\"\n",
    "    Full generation loop in XLA - no Python sync points.\n",
    "    \n",
    "    Returns: (output_tokens, num_generated)\n",
    "    \"\"\"\n",
    "    # Initialize KV cache\n",
    "    k_cache = jnp.zeros((N_LAYERS, MAX_CONTEXT_LENGTH, N_HEADS, HEAD_DIM))\n",
    "    v_cache = jnp.zeros((N_LAYERS, MAX_CONTEXT_LENGTH, N_HEADS, HEAD_DIM))\n",
    "    \n",
    "    # === PREFILL ===\n",
    "    x = W['embed'][prompt_tokens]\n",
    "    for layer_idx in range(N_LAYERS):\n",
    "        x, k_cache, v_cache = prefill_layer(layer_idx, x, k_cache, v_cache, W)\n",
    "    \n",
    "    x = layer_norm(x, W['ln_f_w'], W['ln_f_b'])\n",
    "    logits = x[-1] @ W['lm_head'].T\n",
    "    \n",
    "    # Sample first token\n",
    "    first_token, key = sample_token(logits, key)\n",
    "    \n",
    "    # Initialize output buffer\n",
    "    output_tokens = jnp.zeros(max_new_tokens, dtype=jnp.int32)\n",
    "    output_tokens = output_tokens.at[0].set(first_token)\n",
    "    \n",
    "    # === DECODE with while_loop ===\n",
    "    # State: (output_tokens, num_generated, k_cache, v_cache, cache_len, key, done)\n",
    "    init_state = (\n",
    "        output_tokens,\n",
    "        jnp.array(1, dtype=jnp.int32),  # num_generated (already have 1)\n",
    "        k_cache,\n",
    "        v_cache,\n",
    "        jnp.array(prompt_len, dtype=jnp.int32),  # cache_len\n",
    "        key,\n",
    "        first_token == STOP_TOKEN_ID,  # done\n",
    "    )\n",
    "    \n",
    "    def cond_fn(state):\n",
    "        _, num_generated, _, _, _, _, done = state\n",
    "        return jnp.logical_and(num_generated < max_new_tokens, ~done)\n",
    "    \n",
    "    def body_fn(state):\n",
    "        output_tokens, num_generated, k_cache, v_cache, cache_len, key, _ = state\n",
    "        \n",
    "        # Get the last generated token\n",
    "        last_token = output_tokens[num_generated - 1]\n",
    "        \n",
    "        # Forward pass through all layers\n",
    "        x = W['embed'][last_token].reshape(1, -1)\n",
    "        \n",
    "        for layer_idx in range(N_LAYERS):\n",
    "            x, k_cache, v_cache = decode_layer(layer_idx, x, k_cache, v_cache, cache_len, W)\n",
    "        \n",
    "        x = layer_norm(x, W['ln_f_w'], W['ln_f_b'])\n",
    "        logits = x[0] @ W['lm_head'].T\n",
    "        \n",
    "        # Sample\n",
    "        next_token, key = sample_token(logits, key)\n",
    "        \n",
    "        # Update state\n",
    "        output_tokens = output_tokens.at[num_generated].set(next_token)\n",
    "        done = next_token == STOP_TOKEN_ID\n",
    "        \n",
    "        return (output_tokens, num_generated + 1, k_cache, v_cache, cache_len + 1, key, done)\n",
    "    \n",
    "    final_state = jax.lax.while_loop(cond_fn, body_fn, init_state)\n",
    "    \n",
    "    output_tokens, num_generated, _, _, _, _, _ = final_state\n",
    "    return output_tokens, num_generated\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    import time\n",
    "    \n",
    "    prompt = \"Hello, World!\"\n",
    "    prompt = format_prompt(prompt)\n",
    "    tokens = get_tokens_for_prompt(prompt)\n",
    "    prompt_len = len(tokens)\n",
    "    max_new = MAX_OUTPUT_TOKENS\n",
    "    \n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Prompt length: {prompt_len} tokens\")\n",
    "    print(f\"Max new tokens: {max_new}\")\n",
    "    print()\n",
    "    \n",
    "    # Warmup / compile\n",
    "    print(\"Compiling (first run)...\")\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    start = time.time()\n",
    "    output_tokens, num_generated = generate(tokens, prompt_len, max_new, STACKED_WEIGHTS, key)\n",
    "    output_tokens.block_until_ready()\n",
    "    first_run = time.time() - start\n",
    "    print(f\"First run (includes compilation): {first_run:.3f}s\")\n",
    "    \n",
    "    # Decode output\n",
    "    num_gen = int(num_generated)\n",
    "    out_list = [int(output_tokens[i]) for i in range(num_gen) if int(output_tokens[i]) != STOP_TOKEN_ID]\n",
    "    print(f\"Generated {len(out_list)} tokens\")\n",
    "    print(f\"Output: {tokenizer.decode(out_list)}\")\n",
    "    print()\n",
    "    \n",
    "    # Second run (cached compilation)\n",
    "    print(\"Second run (cached)...\")\n",
    "    key = jax.random.PRNGKey(123)\n",
    "    start = time.time()\n",
    "    output_tokens, num_generated = generate(tokens, prompt_len, max_new, STACKED_WEIGHTS, key)\n",
    "    output_tokens.block_until_ready()\n",
    "    second_run = time.time() - start\n",
    "    \n",
    "    num_gen = int(num_generated)\n",
    "    out_list = [int(output_tokens[i]) for i in range(num_gen) if int(output_tokens[i]) != STOP_TOKEN_ID]\n",
    "    \n",
    "    print(f\"Second run: {second_run:.3f}s\")\n",
    "    print(f\"Tokens: {len(out_list)}, Speed: {len(out_list)/second_run:.1f} tok/s\")\n",
    "    print(f\"Output: {tokenizer.decode(out_list)}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frawdllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
